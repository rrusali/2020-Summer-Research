{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_codes = ['USW00023130', 'USW00093134']\n",
    "\n",
    "# Hexatic Order Parameter\n",
    "hexOrder = pd.DataFrame()\n",
    "for code in LA_codes:\n",
    "    loc = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Hexatic Order Parameters/'\n",
    "    s2 = '_hexatic_order_parameter.txt'\n",
    "    s = loc + code + s2\n",
    "    \n",
    "    with open(s) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, val[4:]]], columns=['Station', 'Hex Order Average'])\n",
    "        hexOrder = hexOrder.append(temp_df, ignore_index = True)\n",
    "\n",
    "# Find the UHII of LA\n",
    "openpath = \"E:/Old Downloads Folder/Research Stuff/Climate Data/LA_UHII.csv\"\n",
    "with open(openpath) as f:\n",
    "    UHII = pd.read_csv(f, sep = ',')\n",
    "\n",
    "# Find the integral of the first peak from Ovito analyses\n",
    "firstPeakIntegrals = pd.DataFrame()\n",
    "for code in LA_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Coordination Analysis Data/Los Angeles/'\n",
    "    s2 = '_first_peak.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'First Peak Integral'])\n",
    "        firstPeakIntegrals = firstPeakIntegrals.append(temp_df, ignore_index = True)\n",
    "\n",
    "# This code finds the data found from QGIS and the average albedo of every area\n",
    "albedos = pd.DataFrame()\n",
    "for code in LA_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/GIS Maps/Albedo Data/'\n",
    "    s2 = '_weighted_albedo.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'Weighted Albedo'])\n",
    "        albedos = albedos.append(temp_df, ignore_index = True)\n",
    "        \n",
    "# This code finds the clustering data from OVITO and finds the location of the first drop\n",
    "drops = pd.DataFrame()\n",
    "for code in LA_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Coords Folder/Weather Station Coords/Los Angeles/First Drops/'\n",
    "    s2 = '_first_drop.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'First Drop'])\n",
    "        drops = drops.append(temp_df, ignore_index = True)\n",
    "\n",
    "# This code finds the buildings per cluster at the location of the first drop\n",
    "perCluster = pd.DataFrame()\n",
    "for code in LA_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Coords Folder/Weather Station Coords/1 Mile Radius/First Drops/Buildings Per Cluster/'\n",
    "    s2 = '_buildings_per_cluster.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'Buildings Per Cluster'])\n",
    "        perCluster = perCluster.append(temp_df, ignore_index = True)\n",
    "\n",
    "# This code finds the data found from QGIS and the average albedo of every area\n",
    "areaAlbedos = pd.DataFrame()\n",
    "for code in LA_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/GIS Maps/Albedo Data/'\n",
    "    s2 = '_area_no_river_albedo.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'No River Albedo'])\n",
    "        areaAlbedos = areaAlbedos.append(temp_df, ignore_index = True)\n",
    "\n",
    "# This code finds the amount of buildings in the area around the weather station\n",
    "totalBuildings = pd.DataFrame()\n",
    "for code in LA_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Coords Folder/Weather Station Coords/Los Angeles/'\n",
    "    s2 = '_building_coords.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "        \n",
    "    # Divide by 9 divides out the area\n",
    "    temp_df = pd.DataFrame([[code, int(i + 1)/9]], columns=['Station', 'Buildings In Area'])\n",
    "    totalBuildings = totalBuildings.append(temp_df, ignore_index=True)\n",
    "\n",
    "totalBuildings = totalBuildings.set_index(['Station'])\n",
    "areaAlbedos = areaAlbedos.set_index(['Station'])\n",
    "perCluster = perCluster.set_index(['Station'])\n",
    "drops = drops.set_index(['Station'])\n",
    "albedos = albedos.set_index(['Station'])\n",
    "UHII = UHII.set_index(['STATION'])\n",
    "firstPeakIntegrals = firstPeakIntegrals.set_index(['Station'])\n",
    "hexOrder = hexOrder.set_index(['Station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UHI</th>\n",
       "      <th>Buildings In Area</th>\n",
       "      <th>No River Albedo</th>\n",
       "      <th>Buildings Per Cluster</th>\n",
       "      <th>First Drop</th>\n",
       "      <th>Weighted Albedo</th>\n",
       "      <th>First Peak Integral</th>\n",
       "      <th>Hex Order Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USW00023130</th>\n",
       "      <td>2.369735</td>\n",
       "      <td>12756.111111</td>\n",
       "      <td>0.44552</td>\n",
       "      <td>326.968750</td>\n",
       "      <td>396.980</td>\n",
       "      <td>0.496099</td>\n",
       "      <td>1.841924</td>\n",
       "      <td>0.6575574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USW00093134</th>\n",
       "      <td>4.978082</td>\n",
       "      <td>19276.111111</td>\n",
       "      <td>0.47755</td>\n",
       "      <td>53.291793</td>\n",
       "      <td>348.867</td>\n",
       "      <td>0.522232</td>\n",
       "      <td>0.689432</td>\n",
       "      <td>0.657032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  UHI  Buildings In Area  No River Albedo  \\\n",
       "USW00023130  2.369735       12756.111111          0.44552   \n",
       "USW00093134  4.978082       19276.111111          0.47755   \n",
       "\n",
       "             Buildings Per Cluster  First Drop  Weighted Albedo  \\\n",
       "USW00023130             326.968750     396.980         0.496099   \n",
       "USW00093134              53.291793     348.867         0.522232   \n",
       "\n",
       "             First Peak Integral Hex Order Average  \n",
       "USW00023130             1.841924         0.6575574  \n",
       "USW00093134             0.689432          0.657032  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull all of our data into on frame\n",
    "LA_frame = pd.DataFrame()\n",
    "LA_frame = pd.concat([UHII, totalBuildings, areaAlbedos, perCluster, drops, albedos, firstPeakIntegrals, hexOrder], axis=1, sort=False)\n",
    "LA_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing as LA except for NY\n",
    "NY_codes = ['USW00014732']\n",
    "\n",
    "# Hexatic Order Parameter\n",
    "hexOrder = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    loc = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Hexatic Order Parameters/'\n",
    "    s2 = '_hexatic_order_parameter.txt'\n",
    "    s = loc + code + s2\n",
    "    \n",
    "    with open(s) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, val[4:]]], columns=['Station', 'Hex Order Average'])\n",
    "        hexOrder = hexOrder.append(temp_df, ignore_index = True)\n",
    "\n",
    "# Find the UHII of NY\n",
    "openpath = \"E:/Old Downloads Folder/Research Stuff/Climate Data/NY_UHII.csv\"\n",
    "with open(openpath) as f:\n",
    "    UHII = pd.read_csv(f, sep = ',')\n",
    "\n",
    "# Find the integral of the first peak from Ovito analyses\n",
    "firstPeakIntegrals = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Coordination Analysis Data/New York/'\n",
    "    s2 = '_first_peak.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'First Peak Integral'])\n",
    "        firstPeakIntegrals = firstPeakIntegrals.append(temp_df, ignore_index = True)\n",
    "\n",
    "# This code finds the data found from QGIS and the average albedo of every area\n",
    "albedos = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/GIS Maps/Albedo Data/'\n",
    "    s2 = '_weighted_albedo.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'Weighted Albedo'])\n",
    "        albedos = albedos.append(temp_df, ignore_index = True)\n",
    "        \n",
    "# This code finds the clustering data from OVITO and finds the location of the first drop\n",
    "drops = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Coords Folder/Weather Station Coords/New York/First Drops/'\n",
    "    s2 = '_first_drop.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'First Drop'])\n",
    "        drops = drops.append(temp_df, ignore_index = True)\n",
    "\n",
    "# This code finds the buildings per cluster at the location of the first drop\n",
    "perCluster = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Coords Folder/Weather Station Coords/New York/First Drops/Buildings Per Cluster/'\n",
    "    s2 = '_buildings_per_cluster.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'Buildings Per Cluster'])\n",
    "        perCluster = perCluster.append(temp_df, ignore_index = True)\n",
    "\n",
    "# This code finds the data found from QGIS and the average albedo of every area\n",
    "areaAlbedos = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/GIS Maps/Albedo Data/'\n",
    "    s2 = '_area_no_river_albedo.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'No River Albedo'])\n",
    "        areaAlbedos = areaAlbedos.append(temp_df, ignore_index = True)\n",
    "\n",
    "# This code finds the amount of buildings in the area around the weather station\n",
    "totalBuildings = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Coords Folder/Weather Station Coords/New York/'\n",
    "    s2 = '_building_coords.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "        \n",
    "    # Divide by 9 divides out the area\n",
    "    temp_df = pd.DataFrame([[code, int(i + 1)/9]], columns=['Station', 'Buildings In Area'])\n",
    "    totalBuildings = totalBuildings.append(temp_df, ignore_index=True)\n",
    "\n",
    "totalBuildings = totalBuildings.set_index(['Station'])\n",
    "areaAlbedos = areaAlbedos.set_index(['Station'])\n",
    "perCluster = perCluster.set_index(['Station'])\n",
    "drops = drops.set_index(['Station'])\n",
    "albedos = albedos.set_index(['Station'])\n",
    "UHII = UHII.set_index(['STATION'])\n",
    "firstPeakIntegrals = firstPeakIntegrals.set_index(['Station'])\n",
    "hexOrder = hexOrder.set_index(['Station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UHI</th>\n",
       "      <th>Buildings In Area</th>\n",
       "      <th>No River Albedo</th>\n",
       "      <th>Buildings Per Cluster</th>\n",
       "      <th>First Drop</th>\n",
       "      <th>Weighted Albedo</th>\n",
       "      <th>First Peak Integral</th>\n",
       "      <th>Hex Order Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USW00014732</th>\n",
       "      <td>9.819641</td>\n",
       "      <td>12943.888889</td>\n",
       "      <td>0.44777</td>\n",
       "      <td>103.827986</td>\n",
       "      <td>234.117</td>\n",
       "      <td>0.515989</td>\n",
       "      <td>3.024053</td>\n",
       "      <td>0.83766013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  UHI  Buildings In Area  No River Albedo  \\\n",
       "USW00014732  9.819641       12943.888889          0.44777   \n",
       "\n",
       "             Buildings Per Cluster  First Drop  Weighted Albedo  \\\n",
       "USW00014732             103.827986     234.117         0.515989   \n",
       "\n",
       "             First Peak Integral Hex Order Average  \n",
       "USW00014732             3.024053        0.83766013  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull all of our data into on frame\n",
    "NY_frame = pd.DataFrame()\n",
    "NY_frame = pd.concat([UHII, totalBuildings, areaAlbedos, perCluster, drops, albedos, firstPeakIntegrals, hexOrder], axis=1, sort=False)\n",
    "NY_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing as LA except for Nashville\n",
    "NY_codes = ['USC00408238']\n",
    "\n",
    "# Hexatic Order Parameter\n",
    "hexOrder = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    loc = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Hexatic Order Parameters/'\n",
    "    s2 = '_hexatic_order_parameter.txt'\n",
    "    s = loc + code + s2\n",
    "    \n",
    "    with open(s) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, val[4:]]], columns=['Station', 'Hex Order Average'])\n",
    "        hexOrder = hexOrder.append(temp_df, ignore_index = True)\n",
    "\n",
    "# Find the UHII of NY\n",
    "openpath = \"E:/Old Downloads Folder/Research Stuff/Climate Data/Nashville_UHII.csv\"\n",
    "with open(openpath) as f:\n",
    "    UHII = pd.read_csv(f, sep = ',')\n",
    "\n",
    "# Find the integral of the first peak from Ovito analyses\n",
    "firstPeakIntegrals = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Coordination Analysis Data/Nashville/'\n",
    "    s2 = '_first_peak.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'First Peak Integral'])\n",
    "        firstPeakIntegrals = firstPeakIntegrals.append(temp_df, ignore_index = True)\n",
    "\n",
    "# This code finds the data found from QGIS and the average albedo of every area\n",
    "albedos = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/GIS Maps/Albedo Data/'\n",
    "    s2 = '_weighted_albedo.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'Weighted Albedo'])\n",
    "        albedos = albedos.append(temp_df, ignore_index = True)\n",
    "        \n",
    "# This code finds the clustering data from OVITO and finds the location of the first drop\n",
    "drops = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Coords Folder/Weather Station Coords/Nashville/First Drops/'\n",
    "    s2 = '_first_drop.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'First Drop'])\n",
    "        drops = drops.append(temp_df, ignore_index = True)\n",
    "\n",
    "# This code finds the buildings per cluster at the location of the first drop\n",
    "perCluster = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Coords Folder/Weather Station Coords/Nashville/First Drops/Buildings Per Cluster/'\n",
    "    s2 = '_buildings_per_cluster.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'Buildings Per Cluster'])\n",
    "        perCluster = perCluster.append(temp_df, ignore_index = True)\n",
    "\n",
    "# This code finds the data found from QGIS and the average albedo of every area\n",
    "areaAlbedos = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/GIS Maps/Albedo Data/'\n",
    "    s2 = '_area_no_river_albedo.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        val = f.read()\n",
    "        temp_df = pd.DataFrame([[code, float(val)]], columns = ['Station', 'No River Albedo'])\n",
    "        areaAlbedos = areaAlbedos.append(temp_df, ignore_index = True)\n",
    "\n",
    "# This code finds the amount of buildings in the area around the weather station\n",
    "totalBuildings = pd.DataFrame()\n",
    "for code in NY_codes:\n",
    "    s1 = 'E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Coords Folder/Weather Station Coords/Nashville/'\n",
    "    s2 = '_building_coords.txt'\n",
    "    openpath = s1 + code + s2\n",
    "    \n",
    "    with open(openpath) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "        \n",
    "    # Divide by 9 divides out the area\n",
    "    temp_df = pd.DataFrame([[code, int(i + 1)/9]], columns=['Station', 'Buildings In Area'])\n",
    "    totalBuildings = totalBuildings.append(temp_df, ignore_index=True)\n",
    "\n",
    "totalBuildings = totalBuildings.set_index(['Station'])\n",
    "areaAlbedos = areaAlbedos.set_index(['Station'])\n",
    "perCluster = perCluster.set_index(['Station'])\n",
    "drops = drops.set_index(['Station'])\n",
    "albedos = albedos.set_index(['Station'])\n",
    "UHII = UHII.set_index(['STATION'])\n",
    "firstPeakIntegrals = firstPeakIntegrals.set_index(['Station'])\n",
    "hexOrder = hexOrder.set_index(['Station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UHI</th>\n",
       "      <th>Buildings In Area</th>\n",
       "      <th>No River Albedo</th>\n",
       "      <th>Buildings Per Cluster</th>\n",
       "      <th>First Drop</th>\n",
       "      <th>Weighted Albedo</th>\n",
       "      <th>First Peak Integral</th>\n",
       "      <th>Hex Order Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USC00408238</th>\n",
       "      <td>0.664835</td>\n",
       "      <td>6135.666667</td>\n",
       "      <td>0.45108</td>\n",
       "      <td>15.29244</td>\n",
       "      <td>2.074751e+07</td>\n",
       "      <td>0.511616</td>\n",
       "      <td>0.854506</td>\n",
       "      <td>0.68679565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  UHI  Buildings In Area  No River Albedo  \\\n",
       "USC00408238  0.664835        6135.666667          0.45108   \n",
       "\n",
       "             Buildings Per Cluster    First Drop  Weighted Albedo  \\\n",
       "USC00408238               15.29244  2.074751e+07         0.511616   \n",
       "\n",
       "             First Peak Integral Hex Order Average  \n",
       "USC00408238             0.854506        0.68679565  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull all of our data into on frame\n",
    "Nashville_frame = pd.DataFrame()\n",
    "Nashville_frame = pd.concat([UHII, totalBuildings, areaAlbedos, perCluster, drops, albedos, firstPeakIntegrals, hexOrder], axis=1, sort=False)\n",
    "Nashville_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UHI</th>\n",
       "      <th>Buildings In Area</th>\n",
       "      <th>No River Albedo</th>\n",
       "      <th>Buildings Per Cluster</th>\n",
       "      <th>First Drop</th>\n",
       "      <th>Weighted Albedo</th>\n",
       "      <th>First Peak Integral</th>\n",
       "      <th>Hex Order Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USW00023130</th>\n",
       "      <td>2.369735</td>\n",
       "      <td>12756.111111</td>\n",
       "      <td>0.44552</td>\n",
       "      <td>326.968750</td>\n",
       "      <td>3.969800e+02</td>\n",
       "      <td>0.496099</td>\n",
       "      <td>1.841924</td>\n",
       "      <td>0.6575574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USW00093134</th>\n",
       "      <td>4.978082</td>\n",
       "      <td>19276.111111</td>\n",
       "      <td>0.47755</td>\n",
       "      <td>53.291793</td>\n",
       "      <td>3.488670e+02</td>\n",
       "      <td>0.522232</td>\n",
       "      <td>0.689432</td>\n",
       "      <td>0.657032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USW00014732</th>\n",
       "      <td>9.819641</td>\n",
       "      <td>12943.888889</td>\n",
       "      <td>0.44777</td>\n",
       "      <td>103.827986</td>\n",
       "      <td>2.341170e+02</td>\n",
       "      <td>0.515989</td>\n",
       "      <td>3.024053</td>\n",
       "      <td>0.83766013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USC00408238</th>\n",
       "      <td>0.664835</td>\n",
       "      <td>6135.666667</td>\n",
       "      <td>0.45108</td>\n",
       "      <td>15.292440</td>\n",
       "      <td>2.074751e+07</td>\n",
       "      <td>0.511616</td>\n",
       "      <td>0.854506</td>\n",
       "      <td>0.68679565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  UHI  Buildings In Area  No River Albedo  \\\n",
       "USW00023130  2.369735       12756.111111          0.44552   \n",
       "USW00093134  4.978082       19276.111111          0.47755   \n",
       "USW00014732  9.819641       12943.888889          0.44777   \n",
       "USC00408238  0.664835        6135.666667          0.45108   \n",
       "\n",
       "             Buildings Per Cluster    First Drop  Weighted Albedo  \\\n",
       "USW00023130             326.968750  3.969800e+02         0.496099   \n",
       "USW00093134              53.291793  3.488670e+02         0.522232   \n",
       "USW00014732             103.827986  2.341170e+02         0.515989   \n",
       "USC00408238              15.292440  2.074751e+07         0.511616   \n",
       "\n",
       "             First Peak Integral Hex Order Average  \n",
       "USW00023130             1.841924         0.6575574  \n",
       "USW00093134             0.689432          0.657032  \n",
       "USW00014732             3.024053        0.83766013  \n",
       "USC00408238             0.854506        0.68679565  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_frame = pd.concat([LA_frame, NY_frame, Nashville_frame], axis=0)\n",
    "final_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USW00023130</th>\n",
       "      <th>USW00093134</th>\n",
       "      <th>USW00014732</th>\n",
       "      <th>USC00408238</th>\n",
       "      <th>Combined</th>\n",
       "      <th>Variable #1</th>\n",
       "      <th>Variable #2</th>\n",
       "      <th>Variable #3</th>\n",
       "      <th>Intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.405167</td>\n",
       "      <td>0.503279</td>\n",
       "      <td>0.529543</td>\n",
       "      <td>2.165656</td>\n",
       "      <td>0.900911</td>\n",
       "      <td>No River Albedo - 33.476932427375566</td>\n",
       "      <td>Hex Order Average - 17.405603106447074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24.950229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.246184</td>\n",
       "      <td>0.291547</td>\n",
       "      <td>0.655641</td>\n",
       "      <td>3.066349</td>\n",
       "      <td>1.064930</td>\n",
       "      <td>First Peak Integral - -0.37783049762020243</td>\n",
       "      <td>No River Albedo - 40.91903049970703</td>\n",
       "      <td>Hex Order Average - 10.82556462667529</td>\n",
       "      <td>-22.866398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.662506</td>\n",
       "      <td>0.644787</td>\n",
       "      <td>0.459315</td>\n",
       "      <td>1.805902</td>\n",
       "      <td>1.143128</td>\n",
       "      <td>Buildings Per Cluster - -0.007681019104100023</td>\n",
       "      <td>No River Albedo - 39.05511302425165</td>\n",
       "      <td>Hex Order Average - 28.19208638003986</td>\n",
       "      <td>-34.996260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.723154</td>\n",
       "      <td>0.314338</td>\n",
       "      <td>0.376879</td>\n",
       "      <td>3.585613</td>\n",
       "      <td>1.249996</td>\n",
       "      <td>Buildings In Area - 0.00022896823746846508</td>\n",
       "      <td>No River Albedo - 30.35299433223684</td>\n",
       "      <td>Hex Order Average - 10.683454184798425</td>\n",
       "      <td>-19.385176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.416609</td>\n",
       "      <td>0.211066</td>\n",
       "      <td>0.517939</td>\n",
       "      <td>4.102481</td>\n",
       "      <td>1.312024</td>\n",
       "      <td>Weighted Albedo - -34.98531367966032</td>\n",
       "      <td>No River Albedo - 46.53070084885902</td>\n",
       "      <td>Hex Order Average - 10.926095380102506</td>\n",
       "      <td>-7.201716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.908740</td>\n",
       "      <td>0.841916</td>\n",
       "      <td>0.293440</td>\n",
       "      <td>2.656163</td>\n",
       "      <td>1.425065</td>\n",
       "      <td>First Peak Integral - 1.3039544785868058</td>\n",
       "      <td>Buildings In Area - 0.0005814709457127093</td>\n",
       "      <td>Hex Order Average - 23.0843169984373</td>\n",
       "      <td>-18.105414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.699064</td>\n",
       "      <td>0.066112</td>\n",
       "      <td>0.698556</td>\n",
       "      <td>5.328056</td>\n",
       "      <td>1.697947</td>\n",
       "      <td>First Peak Integral - -0.42535150453953263</td>\n",
       "      <td>Weighted Albedo - -34.28544762898377</td>\n",
       "      <td>No River Albedo - 52.65696963236703</td>\n",
       "      <td>-1.640951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.980365</td>\n",
       "      <td>0.571689</td>\n",
       "      <td>0.561255</td>\n",
       "      <td>4.801164</td>\n",
       "      <td>1.728619</td>\n",
       "      <td>First Peak Integral - -0.43119894607338716</td>\n",
       "      <td>Buildings In Area - 0.00022176130329962693</td>\n",
       "      <td>No River Albedo - 37.09715206757245</td>\n",
       "      <td>-13.869159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.059026</td>\n",
       "      <td>0.021750</td>\n",
       "      <td>0.595873</td>\n",
       "      <td>5.546568</td>\n",
       "      <td>1.805804</td>\n",
       "      <td>Weighted Albedo - -51.26374740232677</td>\n",
       "      <td>No River Albedo - 48.28747988640819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.798215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.230065</td>\n",
       "      <td>0.232614</td>\n",
       "      <td>0.535693</td>\n",
       "      <td>5.508569</td>\n",
       "      <td>1.876735</td>\n",
       "      <td>Weighted Albedo - -42.250932872554685</td>\n",
       "      <td>Buildings In Area - 8.273759525386247e-05</td>\n",
       "      <td>No River Albedo - 44.210393023777605</td>\n",
       "      <td>5.493295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.676102</td>\n",
       "      <td>0.028833</td>\n",
       "      <td>0.566062</td>\n",
       "      <td>5.291754</td>\n",
       "      <td>1.890688</td>\n",
       "      <td>Weighted Albedo - -51.368510963210234</td>\n",
       "      <td>Buildings Per Cluster - 0.005234700611187426</td>\n",
       "      <td>No River Albedo - 48.5469701535407</td>\n",
       "      <td>8.485302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.963134</td>\n",
       "      <td>0.917807</td>\n",
       "      <td>0.331868</td>\n",
       "      <td>4.800318</td>\n",
       "      <td>2.003282</td>\n",
       "      <td>Buildings Per Cluster - 0.002633628335112428</td>\n",
       "      <td>Buildings In Area - 0.00037514356828788673</td>\n",
       "      <td>No River Albedo - 24.97618526468557</td>\n",
       "      <td>-9.752035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.928457</td>\n",
       "      <td>1.690201</td>\n",
       "      <td>0.155062</td>\n",
       "      <td>4.909684</td>\n",
       "      <td>2.670851</td>\n",
       "      <td>First Peak Integral - 0.9028322719957226</td>\n",
       "      <td>Buildings Per Cluster - 0.006891255900457071</td>\n",
       "      <td>Buildings In Area - 0.0007115627129443022</td>\n",
       "      <td>-1.313809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.060932</td>\n",
       "      <td>0.031446</td>\n",
       "      <td>0.585347</td>\n",
       "      <td>48885.934557</td>\n",
       "      <td>12221.903070</td>\n",
       "      <td>Weighted Albedo - -59.798952732239606</td>\n",
       "      <td>First Drop - -0.00156670797628144</td>\n",
       "      <td>No River Albedo - 54.26377470366257</td>\n",
       "      <td>10.996432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.214566</td>\n",
       "      <td>0.021938</td>\n",
       "      <td>0.817649</td>\n",
       "      <td>54490.643952</td>\n",
       "      <td>13622.924526</td>\n",
       "      <td>First Peak Integral - -0.7634477142762767</td>\n",
       "      <td>First Drop - 0.0017459811564958137</td>\n",
       "      <td>No River Albedo - 44.1220242055953</td>\n",
       "      <td>-16.065951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.175407</td>\n",
       "      <td>0.431702</td>\n",
       "      <td>0.539859</td>\n",
       "      <td>55336.513861</td>\n",
       "      <td>13834.415207</td>\n",
       "      <td>First Drop - 0.0017731496051424092</td>\n",
       "      <td>No River Albedo - 30.23422683230368</td>\n",
       "      <td>Hex Order Average - 15.46400560949128</td>\n",
       "      <td>-22.388263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    USW00023130  USW00093134  USW00014732   USC00408238      Combined  \\\n",
       "0      0.405167     0.503279     0.529543      2.165656      0.900911   \n",
       "1      0.246184     0.291547     0.655641      3.066349      1.064930   \n",
       "2      1.662506     0.644787     0.459315      1.805902      1.143128   \n",
       "3      0.723154     0.314338     0.376879      3.585613      1.249996   \n",
       "4      0.416609     0.211066     0.517939      4.102481      1.312024   \n",
       "5      1.908740     0.841916     0.293440      2.656163      1.425065   \n",
       "6      0.699064     0.066112     0.698556      5.328056      1.697947   \n",
       "7      0.980365     0.571689     0.561255      4.801164      1.728619   \n",
       "8      1.059026     0.021750     0.595873      5.546568      1.805804   \n",
       "9      1.230065     0.232614     0.535693      5.508569      1.876735   \n",
       "10     1.676102     0.028833     0.566062      5.291754      1.890688   \n",
       "11     1.963134     0.917807     0.331868      4.800318      2.003282   \n",
       "12     3.928457     1.690201     0.155062      4.909684      2.670851   \n",
       "13     1.060932     0.031446     0.585347  48885.934557  12221.903070   \n",
       "14     0.214566     0.021938     0.817649  54490.643952  13622.924526   \n",
       "15     0.175407     0.431702     0.539859  55336.513861  13834.415207   \n",
       "\n",
       "                                      Variable #1  \\\n",
       "0            No River Albedo - 33.476932427375566   \n",
       "1      First Peak Integral - -0.37783049762020243   \n",
       "2   Buildings Per Cluster - -0.007681019104100023   \n",
       "3      Buildings In Area - 0.00022896823746846508   \n",
       "4            Weighted Albedo - -34.98531367966032   \n",
       "5        First Peak Integral - 1.3039544785868058   \n",
       "6      First Peak Integral - -0.42535150453953263   \n",
       "7      First Peak Integral - -0.43119894607338716   \n",
       "8            Weighted Albedo - -51.26374740232677   \n",
       "9           Weighted Albedo - -42.250932872554685   \n",
       "10          Weighted Albedo - -51.368510963210234   \n",
       "11   Buildings Per Cluster - 0.002633628335112428   \n",
       "12       First Peak Integral - 0.9028322719957226   \n",
       "13          Weighted Albedo - -59.798952732239606   \n",
       "14      First Peak Integral - -0.7634477142762767   \n",
       "15             First Drop - 0.0017731496051424092   \n",
       "\n",
       "                                     Variable #2  \\\n",
       "0         Hex Order Average - 17.405603106447074   \n",
       "1            No River Albedo - 40.91903049970703   \n",
       "2            No River Albedo - 39.05511302425165   \n",
       "3            No River Albedo - 30.35299433223684   \n",
       "4            No River Albedo - 46.53070084885902   \n",
       "5      Buildings In Area - 0.0005814709457127093   \n",
       "6           Weighted Albedo - -34.28544762898377   \n",
       "7     Buildings In Area - 0.00022176130329962693   \n",
       "8            No River Albedo - 48.28747988640819   \n",
       "9      Buildings In Area - 8.273759525386247e-05   \n",
       "10  Buildings Per Cluster - 0.005234700611187426   \n",
       "11    Buildings In Area - 0.00037514356828788673   \n",
       "12  Buildings Per Cluster - 0.006891255900457071   \n",
       "13             First Drop - -0.00156670797628144   \n",
       "14            First Drop - 0.0017459811564958137   \n",
       "15           No River Albedo - 30.23422683230368   \n",
       "\n",
       "                                  Variable #3  Intercept  \n",
       "0                                         NaN -24.950229  \n",
       "1       Hex Order Average - 10.82556462667529 -22.866398  \n",
       "2       Hex Order Average - 28.19208638003986 -34.996260  \n",
       "3      Hex Order Average - 10.683454184798425 -19.385176  \n",
       "4      Hex Order Average - 10.926095380102506  -7.201716  \n",
       "5        Hex Order Average - 23.0843169984373 -18.105414  \n",
       "6         No River Albedo - 52.65696963236703  -1.640951  \n",
       "7         No River Albedo - 37.09715206757245 -13.869159  \n",
       "8                                         NaN   8.798215  \n",
       "9        No River Albedo - 44.210393023777605   5.493295  \n",
       "10         No River Albedo - 48.5469701535407   8.485302  \n",
       "11        No River Albedo - 24.97618526468557  -9.752035  \n",
       "12  Buildings In Area - 0.0007115627129443022  -1.313809  \n",
       "13        No River Albedo - 54.26377470366257  10.996432  \n",
       "14         No River Albedo - 44.1220242055953 -16.065951  \n",
       "15      Hex Order Average - 15.46400560949128 -22.388263  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up our predictors from Pittsburgh\n",
    "path = \"E:/Old Downloads Folder/Research Stuff/Jupyter Notebooks/Variable_Combos_1mile.csv\"\n",
    "with open(path) as f:\n",
    "    predictors = pd.read_csv(f, sep=',')    \n",
    "predictors = predictors.drop(['R2'], axis=1)\n",
    "\n",
    "# Drop the rows with predictors we can't use. River things\n",
    "bad_keys = []\n",
    "for key, vals in predictors.iteritems():\n",
    "    banned_vals = ['Area Albedo', 'Distance to River']\n",
    "    index = 0\n",
    "    for val in vals:\n",
    "        val = str(val)\n",
    "        val = val[:val.find(' -')]\n",
    "        if val in banned_vals and index not in bad_keys:\n",
    "            bad_keys.append(index)\n",
    "        index += 1\n",
    "\n",
    "# Reset the index\n",
    "predictors = predictors.drop(bad_keys)\n",
    "predictors = predictors.reset_index()\n",
    "predictors = predictors.drop(['index'], axis=1)\n",
    "\n",
    "# Run the predictions\n",
    "LA_predictions = pd.DataFrame(columns=final_frame.index)\n",
    "for code, data in final_frame.iterrows():\n",
    "    all_predictions = []\n",
    "    \n",
    "    # Loops through the prediction frame row by row\n",
    "    for index, row in predictors.iterrows():\n",
    "        prediction = row['Intercept']\n",
    "        for num in range(1, 4):\n",
    "            col_name = 'Variable #' + str(num)\n",
    "            coeff = row[col_name]\n",
    "            if str(coeff) != 'nan':\n",
    "                coeff_name = coeff[:coeff.find(' -')]\n",
    "                coeff_val = float(coeff[coeff.find('- ') + 2:])\n",
    "                \n",
    "                LA_val = float(data[coeff_name])\n",
    "                prediction += LA_val * coeff_val\n",
    "        \n",
    "        all_predictions.append(prediction)\n",
    "    \n",
    "    # Subtract the actual UHII from the predicted UHII\n",
    "    LA_predictions[code] = [x - data['UHI'] for x in all_predictions]\n",
    "\n",
    "# LA_predictions['USW00023130'] = abs(LA_predictions['USW00023130']/final_frame['UHI'][0])\n",
    "# LA_predictions['USW00093134'] = abs(LA_predictions['USW00093134']/final_frame['UHI'][1])\n",
    "\n",
    "for i in range(len(LA_predictions.columns)):\n",
    "    col_name = LA_predictions.columns[i]\n",
    "    LA_predictions[col_name] = abs(LA_predictions[col_name]/final_frame['UHI'][i])\n",
    "    \n",
    "#     # Gods of coding please forgive me for this\n",
    "#     if i == 0:\n",
    "#         LA_predictions['Combined_3mile'] = LA_predictions[col_name]\n",
    "#     elif i == 1:\n",
    "#         LA_predictions['Combined_3mile'] = LA_predictions['Combined_3mile'].add(LA_predictions[col_name])\n",
    "#         LA_predictions['Combined_3mile'] = LA_predictions['Combined_3mile'].divide(2)\n",
    "#     elif i == 2:\n",
    "#         LA_predictions['Combined_1mile'] = LA_predictions[col_name]\n",
    "#     else:\n",
    "#         LA_predictions['Combined_1mile'] = LA_predictions['Combined_1mile'].add(LA_predictions[col_name])\n",
    "#         LA_predictions['Combined_1mile'] = LA_predictions['Combined_1mile'].divide(2)\n",
    "\n",
    "LA_predictions['Combined'] = LA_predictions.sum(axis=1)/len(LA_predictions.columns)\n",
    "# LA_predictions['Combined'] = LA_predictions['Combined_1mile'] + LA_predictions['Combined_3mile']\n",
    "# LA_predictions['Combined'] = LA_predictions['Combined'].divide(2)\n",
    "\n",
    "LA_predictions = pd.concat([LA_predictions, predictors], axis=1, sort=False)\n",
    "\n",
    "LA_predictions = LA_predictions.sort_values(by=['Combined'])\n",
    "LA_predictions = LA_predictions.reset_index()\n",
    "LA_predictions = LA_predictions.drop(['index'], axis=1)\n",
    "LA_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
